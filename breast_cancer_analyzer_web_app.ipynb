{
  "cells": [
    {
      "metadata": {
        "_uuid": "9a87801b30172e0b5819a1dbced38e881c7264bd",
        "id": "_3gXtSaMc9M-"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 1 - IDC Model"
      ]
    },
    {
      "metadata": {
        "_uuid": "fb2bd8f0254cc961a61af1233e3ab167a8594fa8",
        "id": "Uf6b2QsVc9M_"
      },
      "cell_type": "markdown",
      "source": [
        "Dans cette section, nous allons créer le modèle IDC. Ce modèle prédira la présence ou l'absence de carcinome canalaire infiltrant.\n",
        "\n",
        "**Ensemble de données:**\n",
        "\n",
        "Nous utiliserons l'ensemble de données \"Images histopathologiques du sein\". Cet ensemble de données est composé de 277 524 fragments d'images de taille 50x50 (198 738 négatifs pour le IDC et 78 786 positifs pour le IDC). Les images sont au format PNG.\n",
        "\n",
        "**Résultats:**\n",
        "\n",
        "Notre modèle de réseau de neurones convolutionnels (CNN) atteindra une précision et un score F1 supérieurs à 0,85. Cela est basé sur un seuil de classification de 0,5. Il convient de noter que les créateurs du document lié à cet ensemble de données ont utilisé un seuil de 0,29.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "X-chHOLoc9M_"
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(101)\n",
        "from tensorflow.compat.v1 import set_random_seed\n",
        "set_random_seed(101)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import imageio\n",
        "import skimage\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d52f02b7103dac5130ccc5cfd2222a9f8c7a1b6b",
        "id": "P_dtQPA9c9M_"
      },
      "cell_type": "code",
      "source": [
        "#Nombre d'échantillons que nous voulons dans chaque classe. Nombre total d'images utilisées = SAMPLE_SIZE X 2\n",
        "#La classe minoritaire est la classe 1 avec 78 786 échantillons.\n",
        "\n",
        "SAMPLE_SIZE = 78786\n",
        "\n",
        "IMAGE_SIZE = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5rUYjH2OVXRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d52d2ffda062945825b2458824cae26019059f57",
        "id": "NRpwOggLc9M_"
      },
      "cell_type": "markdown",
      "source": [
        "###Quels fichiers sont disponibles ?\n",
        "\n",
        "Les images sont regroupées dans 279 dossiers selon l'ID du patient. Chaque dossier de patient a deux sous-dossiers regroupant les images de la même classe --> 0 ou 1. Il y a beaucoup de dossiers avec lesquels travailler."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe3a2b7c84dfa44b46d6ec069c09c5524657e802",
        "_kg_hide-output": true,
        "id": "ra5ySyvec9M_"
      },
      "cell_type": "code",
      "source": [
        "os.listdir('../input/IDC_regular_ps50_idx5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7db37c5f6d92953e21eaa37ce246df05dbeed0c1",
        "id": "GySON9OGc9NA"
      },
      "cell_type": "code",
      "source": [
        "#Vérifier le nombre de dossiers de patients.\n",
        "\n",
        "patients = os.listdir('../input/IDC_regular_ps50_idx5')\n",
        "\n",
        "len(patients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd97c892d31c99910e1a069cfd6e4b838e270995",
        "id": "Yf0tOBCBc9NA"
      },
      "cell_type": "markdown",
      "source": [
        "###Copier toutes les images dans un seul répertoire\n",
        "Cela facilitera le travail avec ces données."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a01865c676af839aa5037278d74222c738e30179",
        "id": "ouqMWDtsc9NA"
      },
      "cell_type": "code",
      "source": [
        "# Create a new directory to store all available images\n",
        "all_images_dir = 'all_images_dir'\n",
        "os.mkdir(all_images_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95b68d456cacf8f212832809b8a18d9a0bc7101c",
        "id": "LN96pym4c9NA"
      },
      "cell_type": "code",
      "source": [
        "# check that the new diectory has been created\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d82447a2f4d1d0e862ffcb3ec48e764c159dbc55",
        "id": "15Ygb1wec9NA"
      },
      "cell_type": "code",
      "source": [
        "# This code copies all images from their seperate folders into the same\n",
        "# folder called all_images_dir.\n",
        "\n",
        "# Create a list with all the patient id numbers.\n",
        "# Each patient id folder has 2 sub folders --> folder 0 and folder 1\n",
        "\n",
        "# Example:\n",
        "    # '10285'\n",
        "        # '0'\n",
        "        # '1'\n",
        "\n",
        "# create a list of all patient id's\n",
        "patient_list = os.listdir('../input/IDC_regular_ps50_idx5')\n",
        "\n",
        "for patient in patient_list:\n",
        "\n",
        "    path_0 = '../input/IDC_regular_ps50_idx5/' + str(patient) + '/0'\n",
        "    path_1 = '../input/IDC_regular_ps50_idx5/' + str(patient) + '/1'\n",
        "\n",
        "\n",
        "    # create a list of all files in folder 0\n",
        "    file_list_0 = os.listdir(path_0)\n",
        "    # create a list of list all file in folder 1\n",
        "    file_list_1 = os.listdir(path_1)\n",
        "\n",
        "    # move the 0 images to all_images_dir\n",
        "    for fname in file_list_0:\n",
        "\n",
        "        # source path to image\n",
        "        src = os.path.join(path_0, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(all_images_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "    # move the 1 images to all_images_dir\n",
        "    for fname in file_list_1:\n",
        "\n",
        "        # source path to image\n",
        "        src = os.path.join(path_1, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(all_images_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f25b3700f97cbd5f55e77ffdcdde2dc813c95f5",
        "id": "axuqKHp8c9NA"
      },
      "cell_type": "code",
      "source": [
        "# check how many images are in all_images_dir\n",
        "# should be 277,524\n",
        "\n",
        "# size: 2.5GB\n",
        "\n",
        "len(os.listdir('all_images_dir'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b14eb7d4263990c0a9dcba0aa01ef56224accb0",
        "id": "RSttksPIc9NB"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a dataframe containing all the information"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2450c640a1e91bb7ddc8541f0f15f8c328a1bcf2",
        "id": "80J8gH1xc9NB"
      },
      "cell_type": "code",
      "source": [
        "image_list = os.listdir('all_images_dir')\n",
        "\n",
        "df_data = pd.DataFrame(image_list, columns=['image_id'])\n",
        "\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d20cd5b2b51a96e5b3e0a3252c826b93cbd25ef",
        "id": "Z8qHXoUkc9NB"
      },
      "cell_type": "code",
      "source": [
        "# Define Helper Functions\n",
        "\n",
        "# Each file name has this format:\n",
        "# '14211_idx5_x2401_y1301_class1.png'\n",
        "\n",
        "def extract_patient_id(x):\n",
        "    # split into a list\n",
        "    a = x.split('_')\n",
        "    # the id is the first index in the list\n",
        "    patient_id = a[0]\n",
        "\n",
        "    return patient_id\n",
        "\n",
        "def extract_target(x):\n",
        "    # split into a list\n",
        "    a = x.split('_')\n",
        "    # the target is part of the string in index 4\n",
        "    b = a[4]\n",
        "    # the ytarget i.e. 1 or 2 is the 5th index of the string --> class1\n",
        "    target = b[5]\n",
        "\n",
        "    return target\n",
        "\n",
        "# extract the patient id\n",
        "\n",
        "# create a new column called 'patient_id'\n",
        "df_data['patient_id'] = df_data['image_id'].apply(extract_patient_id)\n",
        "# create a new column called 'target'\n",
        "df_data['target'] = df_data['image_id'].apply(extract_target)\n",
        "\n",
        "df_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "297e38d8fccb01cebc5d31dfe50d8f9de86a8351",
        "id": "extKoNPYc9NB"
      },
      "cell_type": "code",
      "source": [
        "df_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6dda72185d30b21abb8989038124c488f3a6dc90",
        "id": "s75pRMZJc9NB"
      },
      "cell_type": "markdown",
      "source": [
        "### Display a random sample of train images by class"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "a2def6b0762c4aba4b474ac386bb6cfaf3649311",
        "id": "PpO8txX9c9NB"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
        "\n",
        "    \"\"\"\n",
        "    Give a column in a dataframe,\n",
        "    this function takes a sample of each class and displays that\n",
        "    sample on one row. The sample size is the same as figure_cols which\n",
        "    is the number of columns in the figure.\n",
        "    Because this function takes a random sample, each time the function is run it\n",
        "    displays different images.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
        "    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols,\n",
        "                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n",
        "    # draw a number of images for each location\n",
        "    for i, cat in enumerate(categories):\n",
        "        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n",
        "        for j in range(0,figure_cols):\n",
        "            file=IMAGE_PATH + sample.iloc[j]['image_id']\n",
        "            im=cv2.imread(file)\n",
        "            ax[i, j].imshow(im, resample=True, cmap='gray')\n",
        "            ax[i, j].set_title(cat, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c71f69b0edbb1999851ed12f9e8bdae7ef939a3",
        "id": "E43NgYBsc9NB"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = 'all_images_dir/'\n",
        "\n",
        "draw_category_images('target',4, df_data, IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a16506d07e5f102b1fdb172fa0ba5f5202a5d533",
        "id": "V_rzlj2bc9NC"
      },
      "cell_type": "markdown",
      "source": [
        "### Balance the class distribution"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f15793d9606cde40aabf53dfdc1816824f72b592",
        "id": "A5Y1mh5lc9NC"
      },
      "cell_type": "code",
      "source": [
        "# What is the class distribution?\n",
        "\n",
        "df_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dbf91ea28135821c4aab3acb628ac8292df69d94",
        "id": "akfyXCDkc9NC"
      },
      "cell_type": "code",
      "source": [
        "# take a sample of the majority class 0 (total = 198738)\n",
        "df_0 = df_data[df_data['target'] == '0'].sample(SAMPLE_SIZE, random_state=101)\n",
        "# take a sample of class 1 (total = 78786)\n",
        "df_1 = df_data[df_data['target'] == '1'].sample(SAMPLE_SIZE, random_state=101)\n",
        "\n",
        "# concat the two dataframes\n",
        "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Check the new class distribution\n",
        "df_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6e14c3bdb999ab0c3acda58c689f73e90476381",
        "id": "4jyHJE0Mc9NC"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the train and  val sets\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08fe5aec1a86b64e914edc75e9b0c785dd9e00b4",
        "id": "s_qKtAqLc9NC"
      },
      "cell_type": "code",
      "source": [
        "# train_test_split\n",
        "\n",
        "# stratify=y creates a balanced validation set.\n",
        "y = df_data['target']\n",
        "\n",
        "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
        "\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9fca5b1044b35b0ba6e4103e135dc4e4f69bf1f",
        "id": "14nicQAXc9NC"
      },
      "cell_type": "code",
      "source": [
        "df_train['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6bb24212bd0a4637c6a02c0187ed474c30745990",
        "id": "PCslsSl1c9NC"
      },
      "cell_type": "code",
      "source": [
        "df_val['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c0eb1110f124d841159a4312f52f1e9466c2b14",
        "id": "eF74XvTMc9NC"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Directory Structure"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c78886470314cdc844487570f672a9afae61587d",
        "id": "UyrqbOMFc9ND"
      },
      "cell_type": "code",
      "source": [
        "# Create a new directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "\n",
        "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
        "\n",
        "# now we create 2 folders inside 'base_dir':\n",
        "\n",
        "# train_dir\n",
        "    # a_no_idc\n",
        "    # b_has_idc\n",
        "\n",
        "# val_dir\n",
        "    # a_no_idc\n",
        "    # b_has_idc\n",
        "\n",
        "\n",
        "\n",
        "# create a path to 'base_dir' to which we will join the names of the new folders\n",
        "# train_dir\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# val_dir\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "\n",
        "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
        "# Inside each folder we create seperate folders for each class\n",
        "\n",
        "# create new folders inside train_dir\n",
        "a_no_idc = os.path.join(train_dir, 'a_no_idc')\n",
        "os.mkdir(a_no_idc)\n",
        "b_has_idc = os.path.join(train_dir, 'b_has_idc')\n",
        "os.mkdir(b_has_idc)\n",
        "\n",
        "\n",
        "# create new folders inside val_dir\n",
        "a_no_idc = os.path.join(val_dir, 'a_no_idc')\n",
        "os.mkdir(a_no_idc)\n",
        "b_has_idc = os.path.join(val_dir, 'b_has_idc')\n",
        "os.mkdir(b_has_idc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7250bdad70673cf1a4ce5f0a53911ff03f029527",
        "id": "qYyxYJddc9ND"
      },
      "cell_type": "code",
      "source": [
        "# check that the folders have been created\n",
        "os.listdir('base_dir/train_dir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "868757fc1d72fc1c54adfac6185e0354f7a4e50c",
        "id": "K0oEL4npc9ND"
      },
      "cell_type": "markdown",
      "source": [
        "### Transfer the images into the folders¶"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f8edcb3172f2583c165b1ab18dedaba8261b9ea",
        "id": "OptlIWg0c9NK"
      },
      "cell_type": "code",
      "source": [
        "# Set the id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de23e2288f785db71eacbb55b8a284e5902ec04e",
        "id": "nleqnaxjc9NK"
      },
      "cell_type": "code",
      "source": [
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "\n",
        "\n",
        "# Transfer the train images\n",
        "\n",
        "for image in train_list:\n",
        "\n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    target = df_data.loc[image,'target']\n",
        "\n",
        "    # these must match the folder names\n",
        "    if target == '0':\n",
        "        label = 'a_no_idc'\n",
        "    if target == '1':\n",
        "        label = 'b_has_idc'\n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(train_dir, label, fname)\n",
        "    # move the image from the source to the destination\n",
        "    shutil.move(src, dst)\n",
        "\n",
        "\n",
        "# Transfer the val images\n",
        "\n",
        "for image in val_list:\n",
        "\n",
        "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
        "    fname = image\n",
        "    # get the label for a certain image\n",
        "    target = df_data.loc[image,'target']\n",
        "\n",
        "    # these must match the folder names\n",
        "    if target == '0':\n",
        "        label = 'a_no_idc'\n",
        "    if target == '1':\n",
        "        label = 'b_has_idc'\n",
        "\n",
        "\n",
        "    # source path to image\n",
        "    src = os.path.join(all_images_dir, fname)\n",
        "    # destination path to image\n",
        "    dst = os.path.join(val_dir, label, fname)\n",
        "    # move the image from the source to the destination\n",
        "    shutil.move(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e895302c8c74f7e5e0d9b52e8d564144f082186",
        "id": "UddroTo1c9NP"
      },
      "cell_type": "code",
      "source": [
        "# check how many train images we have in each folder\n",
        "\n",
        "print(len(os.listdir('base_dir/train_dir/a_no_idc')))\n",
        "print(len(os.listdir('base_dir/train_dir/b_has_idc')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1e7e50cef260226eed29bb11742c08bbac1287c",
        "id": "AvBJlpbfc9NP"
      },
      "cell_type": "code",
      "source": [
        "# check how many val images we have in each folder\n",
        "\n",
        "print(len(os.listdir('base_dir/val_dir/a_no_idc')))\n",
        "print(len(os.listdir('base_dir/val_dir/b_has_idc')))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "722fee40665f455fa038ae4af7412dd1fce8849f",
        "id": "ROM0Aigsc9NQ"
      },
      "cell_type": "code",
      "source": [
        "# End of Data Preparation\n",
        "### ================================================================================== ###\n",
        "# Start of Model Building"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c3b5228e6ada5ee1edecc63407664eacf5731f1",
        "id": "Qd4z3yPec9NQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Set Up the Generators"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90c1df028e4c15202d6743da05c0711e97bdbcec",
        "id": "p8at28bQc9NQ"
      },
      "cell_type": "code",
      "source": [
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "\n",
        "\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df818b545e53289b585189cf6d1d82ace86c8181",
        "id": "FGpLK8yvc9NQ"
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(train_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=train_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "val_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=val_batch_size,\n",
        "                                        class_mode='categorical')\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_gen = datagen.flow_from_directory(valid_path,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode='categorical',\n",
        "                                        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "404bcc4854384fa18209eb5ee105446d9b481d75",
        "id": "h6tIZHeIc9NQ"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the Model Architecture"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60eae5dac2d5d90dd5a03d0871f3d77650bf8b09",
        "_kg_hide-output": true,
        "id": "2aCy_Ve0c9NQ"
      },
      "cell_type": "code",
      "source": [
        "# Source: https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n",
        "\n",
        "kernel_size = (3,3)\n",
        "pool_size= (2,2)\n",
        "first_filters = 32\n",
        "second_filters = 64\n",
        "third_filters = 128\n",
        "\n",
        "dropout_conv = 0.3\n",
        "dropout_dense = 0.3\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu',\n",
        "                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size = pool_size))\n",
        "model.add(Dropout(dropout_conv))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(dropout_dense))\n",
        "model.add(Dense(2, activation = \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce211aa4b707778b73ac60fe42f13b9eb685a7f5",
        "id": "S9stdxyfc9NR"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02fb3d732dff9af1596b8f56c5ff3dc0bcd101cd",
        "id": "9xFi_U7hc9NR"
      },
      "cell_type": "code",
      "source": [
        "model.compile(Adam(lr=0.0001), loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a27114bb8b6838a675b77abb0ee65a9f72c6e162",
        "id": "wCIVngjMc9NR"
      },
      "cell_type": "code",
      "source": [
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=60, verbose=1,\n",
        "                   callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "78c171dc5909de81001c2374cbfa30f1f9158147",
        "id": "_0AWzVtPc9NR"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model using the val set"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "219b0e9391c490824191c99b295ae47f7bee564c",
        "id": "Eiqa79TTc9NR"
      },
      "cell_type": "code",
      "source": [
        "# get the metric names so we can use evaulate_generator\n",
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "132099a89f8459035bfd45d7b27ac4a0da47b0ae",
        "id": "Dlnrf2VQc9NR"
      },
      "cell_type": "code",
      "source": [
        "# Here the best epoch will be used.\n",
        "\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_acc = \\\n",
        "model.evaluate_generator(test_gen,\n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_acc:', val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "00e74d6b276e8b1dbc5d2b9abe4efb5bed1eea61",
        "id": "vPP-GkZrc9NR"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot the Training Curves"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "f4aa7183e51d9d4598a590e94c7882291eebb514",
        "id": "qkhtkVonc9NS"
      },
      "cell_type": "code",
      "source": [
        "# display the loss and accuracy curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca9a7b03dc412c38bac81aba9d8bb0b6cd80f61b",
        "id": "8Mr8aa51c9NS"
      },
      "cell_type": "markdown",
      "source": [
        "### Make a prediction on the val set\n",
        "We need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24f90dc4b0e618267800b43f0a9e5f736469865f",
        "id": "kvE17lSIc9NS"
      },
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55b4269bf393e9699320a0ccb07de3765a9e0548",
        "id": "2wAubnuzc9NS"
      },
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15972146171e8a5b5588b60e83bece03c8ae217d",
        "id": "SH15wdARc9NS"
      },
      "cell_type": "code",
      "source": [
        "# This is how to check what index keras has internally assigned to each class.\n",
        "test_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b7097ace33c1b81a33526aa581b1a2c16ba9670",
        "id": "4-LSwF5gc9NS"
      },
      "cell_type": "code",
      "source": [
        "# Put the predictions into a dataframe.\n",
        "# The columns need to be oredered to match the output of the previous cell\n",
        "\n",
        "df_preds = pd.DataFrame(predictions, columns=['no_idc', 'has_idc'])\n",
        "\n",
        "df_preds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d73625503d727c2e4b18ed7e4d036f65183b391f",
        "id": "S4zQvt_yc9NT"
      },
      "cell_type": "code",
      "source": [
        "# Get the true labels\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# Get the predicted labels as probabilities\n",
        "y_pred = df_preds['has_idc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1bbd432a630e69684a34aa181786a6d8d4f811bd",
        "id": "oTjdBnpbc9NT"
      },
      "cell_type": "markdown",
      "source": [
        "### What is the AUC Score?"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24b04893c841ed8992560c855756ada0ecb87b7b",
        "id": "8BcTG59Zc9NT"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "28ea2d21008495b0fe0d70887a047042ac06b53d",
        "id": "MY9dAY1Hc9NT"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "af3db45056935a3431d50e836a3fa452acf51df4",
        "id": "E764M0I3c9NT"
      },
      "cell_type": "code",
      "source": [
        "# Source: Scikit Learn website\n",
        "# http://scikit-learn.org/stable/auto_examples/\n",
        "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
        "# selection-plot-confusion-matrix-py\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "643d17f82b0ac82b18e54369180b2e89e42c760c",
        "id": "CIS9ild6c9NT"
      },
      "cell_type": "code",
      "source": [
        "# Get the labels of the test images.\n",
        "\n",
        "test_labels = test_gen.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ec35b798d8cd23eb32b851ebe9085b7310462e3",
        "id": "Ebe-Qyyuc9NT"
      },
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "375f94a739f7f87eba5785676ecf9a6364bf5390",
        "id": "dR4XOFG5c9NU"
      },
      "cell_type": "code",
      "source": [
        "# argmax returns the index of the max value in a row\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a05cf1c00f0e17e62a05a752912a4a6cea992e1c",
        "id": "xkG-6qTfc9NU"
      },
      "cell_type": "code",
      "source": [
        "# Print the label associated with each class\n",
        "test_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4695cb8ee3e8b7397050af6ad98e0993a0e62e66",
        "id": "dfE7XeCac9NU"
      },
      "cell_type": "code",
      "source": [
        "# Define the labels of the class indices. These need to match the\n",
        "# order shown above.\n",
        "cm_plot_labels = ['no_idc', 'has_idc']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a9c45ee48964b8083d3a6bf06be027339ddc185",
        "id": "lnJFqlihc9NU"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Classification Report"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c074dc70027c89f85afbca9246624f12101e1a01",
        "id": "ORWGH0Yfc9NU"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate a classification report\n",
        "\n",
        "# For this to work we need y_pred as binary labels not as probabilities\n",
        "y_pred_binary = predictions.argmax(axis=1)\n",
        "\n",
        "report = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n",
        "\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b740b6dff66339d660a8ee7f39818f6c045a7ff",
        "id": "Yo9y_iuTc9NU"
      },
      "cell_type": "markdown",
      "source": [
        "**Recall **= Given a class, will the classifier be able to detect it?<br>\n",
        "**Precision** = Given a class prediction from a classifier, how likely is it to be correct?<br>\n",
        "**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "5959471e2771fa9cc9a5ed3b212a8da26bf46136",
        "id": "1a7IEVeFc9NU"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert the model to from Keras to Tensorflowjs\n",
        "This conversion needs to be done so that the model can be loaded into the web app."
      ]
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "007e141c772fe63f0383435642d8c3c4a7605260",
        "id": "Uf28BNnxc9NU"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fbcbb9ad6050553920edf2277fc08dcc89d04704",
        "id": "IASZAw6gc9NV"
      },
      "cell_type": "code",
      "source": [
        "# Use the command line conversion tool to convert the model\n",
        "\n",
        "!tensorflowjs_converter --input_format keras model.h5 tfjs_model_1/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c00f9303fe526a2c14d7d237b8824c45f982b659",
        "id": "lwRwlO6Kc9NV"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6543d0726d3ce0cbcae293c5403bcc25257dd527",
        "id": "_rxJijJfc9NV"
      },
      "cell_type": "code",
      "source": [
        "# Delete all_images_dir and base_dir directory to prevent a Kaggle error.\n",
        "# Kaggle allows a max of 500 files to be saved.\n",
        "\n",
        "shutil.rmtree('all_images_dir')\n",
        "shutil.rmtree('base_dir')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}